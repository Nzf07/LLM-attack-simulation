# University of Warwick Thesis-5579496
# LLM-attack-simulation
#### Read the following file carefully!
*** 
#### Background
This repository will provide a simulation of various attacks that were developed for the dissertation.
The attacks are:
- Prompt Injections (Indirect)
- Insecure Output Handling Techniques (HTML and XSS Injections)
- Denial of Service

***
#### DISCLAIMER :

These attacks need to be simulated in a controlled environment. The researcher won't be accountable for any damage caused.


*** 

#### USAGE :
The Denial of Service file can be run locally by installing the required packages. However, to simulate the prompt Injection the user requires access to an OpenAI API key.  
```
openai.api_key  = getpass("Please enter your OpenAI API Key: ")
```
Depending on the environment the notebook is being run in, if it is a Google Colab session then the user might need to restart a session and run the cells again. 


## NOTE: This code is functional as of 2 September 2024!

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/nazeef-hasan-khan/)
